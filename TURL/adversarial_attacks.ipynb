{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except:\n",
    "    from tensorboardX import SummaryWriter\n",
    "\n",
    "from tqdm import trange\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from data_loader.hybrid_data_loaders import *\n",
    "from data_loader.header_data_loaders import *\n",
    "from data_loader.CT_Wiki_data_loaders import *\n",
    "from data_loader.RE_data_loaders import *\n",
    "from data_loader.EL_data_loaders import *\n",
    "from model.configuration import TableConfig\n",
    "from model.model import HybridTableMaskedLM, HybridTableCER, TableHeaderRanking, HybridTableCT,HybridTableEL,HybridTableRE,BertRE\n",
    "from model.transformers import BertConfig,BertTokenizer, WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n",
    "from utils.util import *\n",
    "from baselines.row_population.metric import average_precision,ndcg_at_k\n",
    "from baselines.cell_filling.cell_filling import *\n",
    "from model import metric\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'CER': (TableConfig, HybridTableCER, BertTokenizer),\n",
    "    'CF' : (TableConfig, HybridTableMaskedLM, BertTokenizer),\n",
    "    'HR': (TableConfig, TableHeaderRanking, BertTokenizer),\n",
    "    'CT': (TableConfig, HybridTableCT, BertTokenizer),\n",
    "    'EL': (TableConfig, HybridTableEL, BertTokenizer),\n",
    "    'RE': (TableConfig, HybridTableRE, BertTokenizer),\n",
    "    'REBERT': (BertConfig, BertRE, BertTokenizer)\n",
    "}\n",
    "\n",
    "# set data directory, this will be used to load test data\n",
    "data_dir = r\"G:\\CPSC448\\TURL\\data\\wikitables_v2\"\n",
    "\n",
    "config_name = \"configs/table-base-config_v2.json\"\n",
    "device = torch.device('cuda')\n",
    "# load entity vocab from entity_vocab.txt\n",
    "entity_vocab = load_entity_vocab(data_dir, ignore_bad_title=True, min_ent_count=2)\n",
    "entity_wikid2id = {entity_vocab[x]['wiki_id']:x for x in entity_vocab}\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "type_vocab = load_type_vocab(data_dir)\n",
    "entity_vocab = load_entity_vocab(data_dir, ignore_bad_title=True, min_ent_count=2)\n",
    "\n",
    "id2type = {idx:t for t, idx in type_vocab.items()}\n",
    "t2d_invalid = set()\n",
    "\n",
    "def average_precision(output, relevance_labels):\n",
    "    with torch.no_grad():\n",
    "        sorted_output = torch.argsort(output, dim=-1, descending=True)\n",
    "        sorted_labels = torch.gather(relevance_labels, -1, sorted_output).float()\n",
    "        cum_correct = torch.cumsum(sorted_labels, dim=-1)\n",
    "        cum_precision = cum_correct / torch.arange(start=1,end=cum_correct.shape[-1]+1, device=cum_correct.device)[None, :]\n",
    "        cum_precision = cum_precision * sorted_labels\n",
    "        total_valid = torch.sum(sorted_labels, dim=-1)\n",
    "        total_valid[total_valid==0] = 1\n",
    "        average_precision = torch.sum(cum_precision, dim=-1)/total_valid\n",
    "\n",
    "    return average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = r\"G:\\CPSC448\\TURL\\data\\wikitables_v2\\procressed_WikiCT\\test.pickle\"\n",
    "CHECKPOINTS = [\n",
    "    r\"G:\\CPSC448\\TURL\\data\\pre-trained_models\\checkpoints/0/pytorch_model.bin\",\n",
    "    r\"G:\\CPSC448\\TURL\\data\\pre-trained_models\\checkpoints/1/pytorch_model.bin\",\n",
    "    r\"G:\\CPSC448\\TURL\\data\\pre-trained_models\\checkpoints/2/pytorch_model.bin\",\n",
    "    r\"G:\\CPSC448\\TURL\\data\\pre-trained_models\\checkpoints/3/pytorch_model.bin\",\n",
    "    r\"G:\\CPSC448\\TURL\\data\\pre-trained_models\\checkpoints/4/pytorch_model.bin\",\n",
    "    r\"G:\\CPSC448\\TURL\\data\\pre-trained_models\\checkpoints/5/pytorch_model.bin\"\n",
    "]\n",
    "TEST_JSON_ALL = r\"G:\\CPSC448\\TURL\\data\\wikitables_v2\\test.all_table_col_type.json\"\n",
    "TEST_JSON = r\"G:\\CPSC448\\TURL\\data\\wikitables_v2\\test.table_col_type.json\"\n",
    "with open(TEST_JSON_ALL, 'r') as f:\n",
    "    ALL_TABLES = json.load(f)\n",
    "with open(os.path.join(data_dir, 'test.table_col_type.json'), 'r') as f:\n",
    "    TEST_TABLES = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify json\n",
    "def readTable(json_path, table_num):\n",
    "    with open(json_path, 'r') as f:\n",
    "        return json.load(f)[table_num]\n",
    "\n",
    "def writeJson(json_path, tables):\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(tables, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the logits from prediction using a checkpoint on the test_dataset. \n",
    "# Please also set the mode.\n",
    "def predict(test_dataset, checkpoint, mode):\n",
    "    # Define the evaluation sets\n",
    "    per_type_accuracy = {}\n",
    "    per_type_precision = {}\n",
    "    per_type_recall = {}\n",
    "    per_type_f1 = {}\n",
    "    map = {}\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    f1 = {}\n",
    "    per_table_result = {}\n",
    "    \n",
    "    # Start prediction\n",
    "    print(f\"Mode: {mode}\")\n",
    "    config_class, model_class, _ = MODEL_CLASSES['CT']\n",
    "    config = config_class.from_pretrained(config_name)\n",
    "    config.class_num = len(type_vocab)\n",
    "    config.mode = mode\n",
    "    model = model_class(config, is_simple=True)\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    eval_batch_size = 20\n",
    "    eval_sampler = SequentialSampler(test_dataset)\n",
    "    eval_dataloader = CTLoader(test_dataset, sampler=eval_sampler, batch_size=eval_batch_size, is_train=False)\n",
    "    eval_loss = 0.0\n",
    "    eval_map = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    eval_targets = []\n",
    "    eval_prediction_scores = []\n",
    "    eval_pred = []\n",
    "    eval_mask = []\n",
    "    per_table_result[mode] = {}\n",
    "    \n",
    "    logits = []\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        table_ids, input_tok, input_tok_type, input_tok_pos, input_tok_mask, \\\n",
    "            input_ent_text, input_ent_text_length, input_ent, input_ent_type, input_ent_mask, \\\n",
    "            column_entity_mask, column_header_mask, labels_mask, labels = batch\n",
    "        input_tok = input_tok.to(device)\n",
    "        input_tok_type = input_tok_type.to(device)\n",
    "        input_tok_pos = input_tok_pos.to(device)\n",
    "        input_tok_mask = input_tok_mask.to(device)\n",
    "        input_ent_text = input_ent_text.to(device)\n",
    "        input_ent_text_length = input_ent_text_length.to(device)\n",
    "        input_ent = input_ent.to(device)\n",
    "        input_ent_type = input_ent_type.to(device)\n",
    "        input_ent_mask = input_ent_mask.to(device)\n",
    "        column_entity_mask = column_entity_mask.to(device)\n",
    "        column_header_mask = column_header_mask.to(device)\n",
    "        labels_mask = labels_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if mode == 1:\n",
    "            input_ent_mask = input_ent_mask[:,:,input_tok_mask.shape[1]:]\n",
    "            input_tok = None\n",
    "            input_tok_type = None\n",
    "            input_tok_pos = None\n",
    "            input_tok_mask = None\n",
    "        elif mode == 2:\n",
    "            input_tok_mask = input_tok_mask[:,:,:input_tok_mask.shape[1]]\n",
    "            input_ent_text = None\n",
    "            input_ent_text_length = None\n",
    "            input_ent = None\n",
    "            input_ent_type = None\n",
    "            input_ent_mask = None\n",
    "        elif mode == 3:\n",
    "            input_ent = None\n",
    "        elif mode == 4:\n",
    "            input_ent_mask = input_ent_mask[:,:,input_tok_mask.shape[1]:]\n",
    "            input_tok = None\n",
    "            input_tok_type = None\n",
    "            input_tok_pos = None\n",
    "            input_tok_mask = None\n",
    "            input_ent = None\n",
    "        elif mode == 5:\n",
    "            input_ent_mask = input_ent_mask[:,:,input_tok_mask.shape[1]:]\n",
    "            input_tok = None\n",
    "            input_tok_type = None\n",
    "            input_tok_pos = None\n",
    "            input_tok_mask = None\n",
    "            input_ent_text = None\n",
    "            input_ent_text_length = None\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tok, input_tok_type, input_tok_pos, input_tok_mask,\\\n",
    "                input_ent_text, input_ent_text_length, input_ent, input_ent_type, input_ent_mask, column_entity_mask, column_header_mask, labels_mask, labels)\n",
    "            loss = outputs[0]\n",
    "            prediction_scores = outputs[1]\n",
    "            for l_i in t2d_invalid:\n",
    "                prediction_scores[:,:,l_i] = -1000\n",
    "            for idx, table_id in enumerate(table_ids):\n",
    "                valid = labels_mask[idx].nonzero().max().item()+1\n",
    "                if table_id not in per_table_result[mode]:\n",
    "                    per_table_result[mode][table_id] = [[],labels_mask[idx,:valid],labels[idx,:valid]]\n",
    "                per_table_result[mode][table_id][0].append(prediction_scores[idx,:valid])\n",
    "            ap = metric.average_precision(prediction_scores.view(-1, config.class_num), labels.view((-1, config.class_num)))\n",
    "            map = (ap*labels_mask.view(-1)).sum()/labels_mask.sum()\n",
    "            eval_loss += loss.mean().item()\n",
    "            eval_map += map.item()\n",
    "            eval_targets.extend(labels.view(-1, config.class_num).tolist())\n",
    "            eval_prediction_scores.extend(prediction_scores.view(-1, config.class_num).tolist())\n",
    "            eval_pred.extend((torch.sigmoid(prediction_scores.view(-1, config.class_num))>0.5).tolist())\n",
    "            eval_mask.extend(labels_mask.view(-1).tolist())\n",
    "        nb_eval_steps += 1\n",
    "        # print(loss.shape)\n",
    "        logits.append(prediction_scores)\n",
    "    return logits, per_table_result\n",
    "\n",
    "LENGTH_ALL_TABLES = []\n",
    "\n",
    "for table in ALL_TABLES:\n",
    "    length = 0\n",
    "    for col in table[6]:\n",
    "        if len(col) > length:\n",
    "            length = len(col)\n",
    "    LENGTH_ALL_TABLES.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrappedPredict(tables):\n",
    "    writeJson(TEST_JSON, tables)\n",
    "\n",
    "    if os.path.exists(DATASET_PATH):\n",
    "        os.remove(DATASET_PATH)\n",
    "    test_dataset = WikiCTDataset(data_dir, entity_vocab, type_vocab, max_input_tok=500, src=\"test\", max_length = [50, 10, 10], force_new=False, tokenizer = None)\n",
    "\n",
    "\n",
    "    # Get the logits and the predicted results\n",
    "    logits, per_table_result = predict(test_dataset, CHECKPOINTS[4], 4)\n",
    "    \n",
    "    return logits, per_table_result\n",
    "\n",
    "LOGITS, _ = wrappedPredict(ALL_TABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corr = 0\n",
    "total_valid = 0\n",
    "errors = []\n",
    "for table_id, result in per_table_result[4].items():\n",
    "    prediction_scores, label_mask, label = result\n",
    "    prediction_scores = torch.stack(prediction_scores, 0).mean(0)\n",
    "    current_corr = 0\n",
    "    for col_idx, pred in enumerate(prediction_scores.argmax(-1).tolist()):\n",
    "        current_corr += label[col_idx, pred].item()\n",
    "    total_valid += label_mask.sum().item()\n",
    "    total_corr += current_corr\n",
    "    if current_corr!=label_mask.sum().item():\n",
    "        errors.append(table_id)\n",
    "print(total_corr/total_valid, total_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def extractColumn(file_path, column_index):\n",
    "    column_values = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            columns = line.strip().split('\\t')\n",
    "            if len(columns) > column_index:\n",
    "                column_values.append(columns[column_index])\n",
    "    return column_values\n",
    "\n",
    "def switchEntities(tables, percentage):\n",
    "    entity_list = extractColumn(os.path.join(data_dir, \"entity_vocab.txt\"), 2)\n",
    "    entity_id_list = extractColumn(os.path.join(data_dir, \"entity_vocab.txt\"), 1)\n",
    "    tables_copy = copy.deepcopy(tables)\n",
    "    \n",
    "    for table_index in range (len(tables)):\n",
    "        col_num = len(tables[table_index][6])\n",
    "        entity_position = []\n",
    "        # Get the number of entities\n",
    "        for col_index in range(col_num):\n",
    "            row_num = len(tables[table_index][6][col_index])\n",
    "            for row_index in range(row_num):\n",
    "                entity_position.append([row_index, col_index])\n",
    "        \n",
    "        # Randomly choose entities * percentage entities. random_entity_positions is a list\n",
    "        random_entity_positions = random.sample(entity_position, int(len(entity_position) * percentage))\n",
    "        \n",
    "        \n",
    "        for random_entity_position in random_entity_positions:\n",
    "            # Random index in the list containing all the entities\n",
    "            rand_num = random.randint(0, len(entity_list))\n",
    "            \n",
    "            [random_entity_row, random_entity_col] = random_entity_position\n",
    "            tables_copy[table_index][6][random_entity_col][random_entity_row][1] = [int(entity_id_list[rand_num]), entity_list[rand_num]]\n",
    "                \n",
    "    return tables_copy\n",
    "\n",
    "def maskEntities(tables, percentage):\n",
    "    entity_list = extractColumn(os.path.join(data_dir, \"entity_vocab.txt\"), 2)\n",
    "    entity_id_list = extractColumn(os.path.join(data_dir, \"entity_vocab.txt\"), 1)\n",
    "    tables_copy = copy.deepcopy(tables)\n",
    "    \n",
    "    for table_index in range (len(tables)):\n",
    "        col_num = len(tables[table_index][6])\n",
    "        entity_position = []\n",
    "        # Get the number of entities\n",
    "        for col_index in range(col_num):\n",
    "            row_num = len(tables[table_index][6][col_index])\n",
    "            for row_index in range(row_num):\n",
    "                entity_position.append([row_index, col_index])\n",
    "        \n",
    "        # Randomly choose entities * percentage entities. random_entity_positions is a list\n",
    "        random_entity_positions = random.sample(entity_position, int(len(entity_position) * percentage))\n",
    "        \n",
    "        \n",
    "        for random_entity_position in random_entity_positions:            \n",
    "            [random_entity_row, random_entity_col] = random_entity_position\n",
    "            tables_copy[table_index][6][random_entity_col][random_entity_row][1][1] = 'ENT_MASK'\n",
    "                \n",
    "    return tables_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switched_tables = switchEntities(ALL_TABLES, 0.8)\n",
    "logits, per_table_result = wrappedPredict(switched_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corr = 0\n",
    "total_valid = 0\n",
    "errors = []\n",
    "for table_id, result in per_table_result[4].items():\n",
    "    prediction_scores, label_mask, label = result\n",
    "    prediction_scores = torch.stack(prediction_scores, 0).mean(0)\n",
    "    current_corr = 0\n",
    "    for col_idx, pred in enumerate(prediction_scores.argmax(-1).tolist()):\n",
    "        current_corr += label[col_idx, pred].item()\n",
    "    total_valid += label_mask.sum().item()\n",
    "    total_corr += current_corr\n",
    "    if current_corr!=label_mask.sum().item():\n",
    "        errors.append(table_id)\n",
    "print(total_corr/total_valid, total_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(ALL_TABLES[0][6][])\n",
    "\n",
    "\n",
    "logits, _ = wrappedPredict([ALL_TABLES[859]] * 30)\n",
    "len(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def deleteOutOfRowBound(tables, length_tables, indices_tables, row_idx):\n",
    "    filtered_indices = [i for i in range(len(length_tables)) if length_tables[i] > row_idx]\n",
    "    \n",
    "    length_tables = [length_tables[i] for i in filtered_indices]\n",
    "    tables = [tables[i] for i in filtered_indices]\n",
    "    indices_tables = [indices_tables[i] for i in filtered_indices]\n",
    "    \n",
    "    return tables, length_tables, indices_tables\n",
    "\n",
    "        \n",
    "# Mask the given row of all the tables in tables\n",
    "def maskRowOfTables(tables, row_idx):\n",
    "    for table_idx in range(len(tables)):\n",
    "        for col_idx in range(len(tables[table_idx][6])):\n",
    "            try:\n",
    "                tables[table_idx][6][col_idx][row_idx][1][1] = 'ENT_MASK'\n",
    "            except IndexError:\n",
    "                # We don't care about the index error for incomplete tables\n",
    "                continue\n",
    "        \n",
    "    return tables\n",
    "\n",
    "def writeCSV(table_num, logits_difference_row):\n",
    "    file_path = rf'G:\\CPSC448\\TURL\\data\\logits_difference\\table_{table_num}.csv'\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(logits_difference_row)\n",
    "                \n",
    "    else:\n",
    "        with open(file_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(logits_difference_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGITS has 239 elements, each for a single batch. Each element has a shape of [table_num_in_batch, col_num, 255]\n",
    "table1 = copy.deepcopy(ALL_TABLES[1])\n",
    "del table1[6][0][12:] \n",
    "display(table1)\n",
    "display(LOGITS[0][0][4])\n",
    "type_vocab['time.event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all tables, this will be shorten\n",
    "copy_all_tables = copy.deepcopy(ALL_TABLES)\n",
    "copy_all_lengths = copy.deepcopy(LENGTH_ALL_TABLES)\n",
    "copy_all_table_indices = list(range(len(ALL_TABLES)))\n",
    "\n",
    "row_idx = 0\n",
    "while len(copy_all_tables) > 0 and row_idx < 10:\n",
    "    copy_all_tables, copy_all_lengths, copy_all_table_indices = deleteOutOfRowBound(copy_all_tables, copy_all_lengths, copy_all_table_indices, row_idx)\n",
    "    \n",
    "    if len(copy_all_tables) == 0:\n",
    "        break\n",
    "    \n",
    "    # Remember the tables before masked. For recovery.\n",
    "    temp_tables = copy.deepcopy(copy_all_tables)\n",
    "    copy_all_tables = maskRowOfTables(copy_all_tables, row_idx)\n",
    "    logits_masked, _ = wrappedPredict(copy_all_tables)\n",
    "    \n",
    "    for batch_idx in range(len(logits_masked)):\n",
    "        for table_index_in_batch in range(len(logits_masked[batch_idx])):\n",
    "            # Create a logits difference table\n",
    "            logits_difference_row = []\n",
    "            \n",
    "            # Get the table index among the remaining tables\n",
    "            table_index_in_remaining = table_index_in_batch + 20 * batch_idx\n",
    "            # Get the index among all the tables\n",
    "            table_index_in_all = copy_all_table_indices[table_index_in_remaining]\n",
    "            # Go to LOGITS and get the logits for that table\n",
    "            correct_table_logits = LOGITS[table_index_in_all//20][table_index_in_all%20]\n",
    "            print(correct_table_logits[0][196])\n",
    "            \n",
    "            table = ALL_TABLES[table_index_in_all]\n",
    "            correct_labels = table[7]\n",
    "            col_num = len(correct_labels)\n",
    "            \n",
    "            for col_idx in range(len(correct_labels)):\n",
    "                label_index = type_vocab[correct_labels[col_idx][0]]\n",
    "                \n",
    "                logits_difference_row.append(math.fabs(correct_table_logits[col_idx][label_index].item() - logits_masked[batch_idx][table_index_in_batch][col_idx][label_index].item()))\n",
    "                print(table_index_in_all, \" \", math.fabs(logits_masked[batch_idx][table_index_in_batch][col_idx][label_index].item()))\n",
    "                \n",
    "                \n",
    "            writeCSV(table_index_in_all, logits_difference_row)\n",
    "    # Deal with the logits\n",
    "    ####\n",
    "    # Recover\n",
    "    copy_all_tables = temp_tables\n",
    "    row_idx += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
